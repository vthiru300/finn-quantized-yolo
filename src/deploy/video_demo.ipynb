{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73638acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run face detection on a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "921b5713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from IPython.display import display, Image \n",
    "from driver.driver import io_shape_dict\n",
    "from driver.driver_base import FINNExampleOverlay\n",
    "from utils import (clip_coords, scale_coords, letterbox, \n",
    "                   xywh2xyxy, non_max_suppression,  \n",
    "                   visualize_boxes)\n",
    "from models import Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e160dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(img_org, driver):\n",
    "    img = img_org.copy()\n",
    "    img, ratio, (dw, dh) = letterbox(img, (416,416), auto=False)\n",
    "    img = img[:, :, ::-1]\n",
    "\n",
    "    img = img.astype(np.uint8)\n",
    "    driver_in = np.expand_dims(img, 0)\n",
    "\n",
    "    output = driver.execute(driver_in)\n",
    "    output = scale*output\n",
    "    output = output.transpose(0,3,1,2)\n",
    "\n",
    "    output = torch.from_numpy(output)\n",
    "    pred = detect_head([output])[0]\n",
    "\n",
    "    pred = non_max_suppression(pred, conf_thres=0.10, iou_thres=0.10, classes=None, max_det=20)\n",
    "\n",
    "    # Process predictions\n",
    "    for i, det in enumerate(pred):  # per image\n",
    "\n",
    "        if len(det):\n",
    "            det[:, :4] = scale_coords(img.shape, det[:, :4], img_org.shape).round()\n",
    "\n",
    "            # Write results\n",
    "            for *xyxy, conf, cls in reversed(det):\n",
    "                c = int(cls)  # integer class\n",
    "                label = f'{names[c]} {conf:.2f}'\n",
    "                left, top = int(xyxy[0]), int(xyxy[1])\n",
    "                right, bottom = int(xyxy[2]), int(xyxy[3])\n",
    "                cv2.rectangle(img_org, (left, top), (right, bottom), (0,255,0), thickness=1)\n",
    "            \n",
    "    return img_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2780d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = FINNExampleOverlay(\n",
    "    bitfile_name=\"./bitfile/finn-accel.bit\",\n",
    "    platform=\"zynq-iodma\",\n",
    "    io_shape_dict=io_shape_dict,\n",
    "    batch_size=1,\n",
    "    runtime_weight_dir=\"runtime_weights/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b6a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['face']\n",
    "nc  = 1\n",
    "anchors = np.array([[10,14,23,27,37,58]]) / np.array([32])\n",
    "scale = np.load(\"./bitfile/scale.npy\")\n",
    "detect_head = Detect(nc, anchors)\n",
    "process_rate = 5 # Process frame at every nth frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8c2697d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-63e5340d3b35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframe_number\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprocess_rate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpeg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-40396a494527>\u001b[0m in \u001b[0;36minference\u001b[0;34m(img_org, driver)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_org\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_org\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mletterbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture(\"../../inputs/videos/sample.mp4\")\n",
    "display_handle=display(None, display_id=True)\n",
    "try:\n",
    "    frame_number = 0\n",
    "    while True:\n",
    "        _, frame = video.read()\n",
    "        if frame_number % process_rate == 0:\n",
    "            frame = inference(frame, driver)\n",
    "           \n",
    "            _, frame = cv2.imencode('.jpeg', frame)\n",
    "            display_handle.update(Image(data=frame.tobytes()))\n",
    "        frame_number += 1\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    video.release()\n",
    "    display_handle.update(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b920d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
